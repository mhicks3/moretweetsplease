{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bef4440-1673-4f6e-805a-4a6a6a76a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd\n",
    "import csv\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from textblob import TextBlob\n",
    "import sys\n",
    "import os\n",
    "import nltk\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import text2emotion as te\n",
    "import seaborn as sns\n",
    "import time\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec4d54-d36f-4f87-a7b6-9cef89c73de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARIABLES TO CHANGE\n",
    "\n",
    "start_pos = 0 #change to not start at the beginning of your tweet corpus\n",
    "output_csv = 'output_proc.csv'\n",
    "match_csv = 'tweet1.csv'# the tweet you want to match\n",
    "tweets_csv = 'data.csv' #'data.csv' #'CapnMarvel_2.csv' # the corpus of tweets you want to draw from\n",
    "\n",
    "\n",
    "#Syntactic options\n",
    "check_syntax = True\n",
    "min_syntax = .6\n",
    "\n",
    "#Semantic options\n",
    "check_semantic = True\n",
    "min_semantic = .6\n",
    "check_SBERT = True\n",
    "check_GUSE = False\n",
    "min_SBERT = min_GUSE = min_semantic\n",
    "\n",
    "#Sentiment options\n",
    "check_sentiment = True\n",
    "sentiment_type = 'EMOTION' #'STANDARD' OR 'EMOTION' \n",
    "min_sentiment = .6\n",
    "\n",
    "#Target options\n",
    "check_target = False\n",
    "min_target = .6\n",
    "\n",
    "#BEND options\n",
    "check_bend = False\n",
    "min_bend = .6\n",
    "\n",
    "\n",
    "match_array = [check_syntax, check_semantic, check_sentiment, check_target, check_bend]\n",
    "min_array = [min_syntax, min_semantic, min_sentiment, min_target, min_bend]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82713e0a-ffab-4488-94e0-d1ffeaffb8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output file\n",
    "csvFile = open(output_csv, \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb335a-f547-4c2c-83c9-263e711acb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open ref document\n",
    "#extract text\n",
    "df_ref = pd.read_csv(match_csv)\n",
    "features_ref = ['text']\n",
    "ref_text = df_ref[features_ref].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05625169-209b-4a56-aac0-fc9609d2554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open draw db\n",
    "#extract text\n",
    "df_draw = pd.read_csv(tweets_csv)\n",
    "features_draw = ['text']\n",
    "draw_text = df_draw[features_draw].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d441d9cc-59c5-492c-9d82-df62c6a140b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYNTACTIC+\n",
    "#word2vec\n",
    "if check_syntax:\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    syntax_1 = nlp(ref_text[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb74ce-b3e1-4a4c-8b03-3b6c4be51a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_match(queue, syntax1, draw_text, nlp, start_pos):\n",
    "    import numpy as np\n",
    "    ranger = len(draw_text)\n",
    "    for n1 in np.arange(start_pos, ranger):\n",
    "        syntax2 = nlp(draw_text[n1][0])\n",
    "        sim_syntax = syntax1.similarity(syntax2)\n",
    "        queue.put(sim_syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e85078-82b0-4033-8238-13e7cb44a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEMANTIC\n",
    "\n",
    "if check_semantic:\n",
    "    #Setup SBERT\n",
    "    if check_SBERT:\n",
    "        multi_model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "        m_emb1 = multi_model.encode(ref_text[0][0])\n",
    "    #Setup Google USE\n",
    "    if check_GUSE:\n",
    "        module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
    "        GUSE_model = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850233a-5757-412d-ad43-40828b17db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilingual_SBERT(queue, memb1, draw_text, min_sem, multi_model, start_pos):\n",
    "    import numpy as np\n",
    "    from sentence_transformers import util\n",
    "    ranger = len(draw_text)\n",
    "    for n1 in np.arange(start_pos, ranger):\n",
    "        m_emb2 = multi_model.encode(draw_text[n1][0])\n",
    "        m_cos_sim = util.cos_sim(memb1, m_emb2)\n",
    "        queue.put(m_cos_sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfce5cb-7406-48b5-ba00-f8f8c4404ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Google_USE(queue, text1, draw_text, min_sem, GUSE_model, start_pos):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    ranger = len(draw_text)\n",
    "    for n1 in np.arange(start_pos, ranger):\n",
    "        text = [text1, draw_text[n1][0]]\n",
    "        embeddings = GUSE_model(text)\n",
    "        similarity = cosine_similarity(embeddings)\n",
    "        queue.put(similarity[0][1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6fc306-472a-4654-b314-13758b7adbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENTIMENT\n",
    "if check_sentiment:\n",
    "    match sentiment_type:\n",
    "        case \"STANDARD\":\n",
    "            nltk.download('vader_lexicon')\n",
    "            sid = SentimentIntensityAnalyzer()\n",
    "            score1b = sid.polarity_scores(ref_text[0][0])\n",
    "            score_list = [float(score1b['neg']),float(score1b['neu']),float(score1b['pos']),float(score1b['compound'])]\n",
    "            score1 = np.array(score_list)\n",
    "        \n",
    "        case \"EMOTION\":\n",
    "            nltk.download('omw-1.4')\n",
    "            score1b = te.get_emotion(ref_text[0][0])\n",
    "            score_list = [float(score1b['Happy']),float(score1b['Angry']),float(score1b['Surprise']),float(score1b['Sad']),float(score1b['Fear'])]\n",
    "            score1 = np.array(score_list)\n",
    "        case _:\n",
    "            print(\"ERROR - YOU DID NOT PROPERLY SPECIFY A METHOD FOR SENTIMENT MATCH. SHOULD BE STANDARD OR EMOTION.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c60743-fc16-4ce3-b1c6-4db453d95179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_match(queue, score_1, draw_text, sentiment_type, start_pos):\n",
    "    #TODO: emotion set takes almost .5s -> fix this\n",
    "    import text2emotion as te\n",
    "    import numpy as np\n",
    "    ranger = len(draw_text)\n",
    "    for n1 in np.arange(start_pos, ranger):\n",
    "        match sentiment_type:\n",
    "            case \"STANDARD\":\n",
    "                score_2b = SentimentIntensityAnalyzer().polarity_scores(draw_text[n1][0])\n",
    "                score2_list = [float(score_2b['neg']),float(score_2b['neu']),float(score_2b['pos']),float(score_2b['compound'])]\n",
    "                score_2 = np.array(score2_list)\n",
    "                interim_sim = util.cos_sim(score_1, score_2)\n",
    "                sentiment_sim = interim_sim[0].item()\n",
    "            case \"EMOTION\":\n",
    "                score2b = te.get_emotion(draw_text[n1][0])\n",
    "                score2_list = [float(score2b['Happy']),float(score2b['Angry']),float(score2b['Surprise']),float(score2b['Sad']),float(score2b['Fear'])]\n",
    "                score_2 = np.array(score2_list)\n",
    "                dist = np.linalg.norm(score_1 - score_2)\n",
    "                sentiment_sim = 1 - (dist / 2.23606797749979) #normalized by highgest possible distanceand subtracted from 1\n",
    "            case _:\n",
    "                print(\"ERROR - YOU DID NOT PROPERLY SPECIFY A METHOD FOR SENTIMENT MATCH. SHOULD BE STANDARD OR EMOTION.\")\n",
    "        queue.put(sentiment_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063a9fb-7c86-4e3d-b17a-29341432dac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from multiprocess import Queue\n",
    "from multiprocess import Process\n",
    "# We are going to iterate over data that was in a beautiful vector friendly data frame \n",
    "# This is a terrible idea and should never be done\n",
    "ranger = len(draw_text)\n",
    "queue1 = Queue()\n",
    "queue2 = Queue()\n",
    "queue3 = Queue()\n",
    "queue4 = Queue()\n",
    "\n",
    "if check_SBERT: \n",
    "    process1 =  Process(target=multilingual_SBERT, args=(queue1, m_emb1, draw_text, min_SBERT, multi_model, start_pos))\n",
    "    process1.start()\n",
    "if check_GUSE:\n",
    "    process2 = Process(target=Google_USE, args=(queue2, ref_text[0][0], draw_text, min_GUSE, GUSE_model, start_pos))\n",
    "    process2.start()\n",
    "if check_sentiment:\n",
    "    process3 = Process(target=sentiment_match, args=(queue3, score1, draw_text, sentiment_type, start_pos))\n",
    "    process3.start()\n",
    "if check_syntax:\n",
    "    process4 = Process(target=word2vec_match, args=(queue4, syntax_1, draw_text, nlp, start_pos))\n",
    "    process4.start()\n",
    "    \n",
    "start_time = time.time()    \n",
    "for n1 in np.arange(start_pos, ranger):\n",
    "    match_final = True\n",
    "    interim_time = time.time()\n",
    "    match_mbert = 0\n",
    "    match_GUSE = 0\n",
    "    if check_SBERT: match_mbert = queue1.get()\n",
    "    if check_GUSE: match_GUSE = queue2.get()\n",
    "    if check_sentiment: interim2 = queue3.get()\n",
    "    if check_syntax: interim0 = queue4.get()\n",
    "    match_array[2] = interim2\n",
    "    match_array[0] = interim0\n",
    "    if check_semantic: \n",
    "        match_array[1] = max(match_mbert, match_GUSE)\n",
    "    #iterate over match array\n",
    "    #match_array = [check_syntax, check_semantic, check_sentiment, check_target, check_bend]\n",
    "    for n2 in np.arange(len(match_array)):\n",
    "        if match_array[n2] != False:\n",
    "            if match_array[n2] >= min_array[n2]:\n",
    "                match_final = match_final and True\n",
    "            else:\n",
    "                match_final = False    \n",
    "    \n",
    "    if match_final:\n",
    "        print(\"FOUND A MATCH WITH TWEET #\" + str(n1))\n",
    "        print(match_array)\n",
    "        #Open OR create the target CSV file\n",
    "        csvFile = open(output_csv, \"a\", newline=\"\", encoding='utf-8')\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(df_draw.iloc[n1])\n",
    "        # When done, close the CSV file\n",
    "        csvFile.close()\n",
    "    print(\"Processed Tweet \" + str(n1) + \" in \" + \"%s seconds ---\" % (time.time() - interim_time))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "temp2 = (time.time() - start_time)/ranger\n",
    "print(\"Avg time per tweet: \" + str(temp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c4dc8b-5b9c-4ffc-abee-b12b41bd1edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
